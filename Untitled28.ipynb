{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e326511e-1b61-4af5-b5f5-61a33bf82753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /opt/anaconda3/lib/python3.12/site-packages (4.3.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/anaconda3/lib/python3.12/site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/anaconda3/lib/python3.12/site-packages (from gensim) (5.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "080e1aaf-1cce-48b5-8ce9-98db803e048d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CondaError: Run 'conda init' before 'conda activate'\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda activate base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81691d8d-f8c8-4d95-aa87-34667e6786c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed dataset saved as 'preprocessed_reviews.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fs/8p641mkj439fhjp80mzj_v_40000gn/T/ipykernel_7870/1789442869.py:118: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.countplot(x='Rating', data=df, palette='viridis')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizations saved in 'plots/' directory\n",
      "PDF report generated: Starbucks_Review_Analysis_Report.pdf\n",
      "\n",
      "Analysis Summary:\n",
      "Total Reviews: 703\n",
      "Rating Distribution:\n",
      "Rating\n",
      "1    450\n",
      "2     98\n",
      "3     33\n",
      "4     39\n",
      "5     83\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sentiment Distribution:\n",
      "Sentiment\n",
      "Positive    380\n",
      "Negative    295\n",
      "Neutral      28\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Starbucks Review Analysis Python Script\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Specify the path to reviews_data.csv here\n",
    "CSV_PATH = '/Users/mo/Downloads/reviews_data.csv'  # Update if CSV is elsewhere\n",
    "\n",
    "# Check for required modules\n",
    "required_modules = ['pandas', 'nltk', 'textblob', 'matplotlib', 'seaborn', 'wordcloud', 'reportlab']\n",
    "missing_modules = []\n",
    "for module in required_modules:\n",
    "    try:\n",
    "        __import__(module)\n",
    "    except ImportError:\n",
    "        missing_modules.append(module)\n",
    "\n",
    "if missing_modules:\n",
    "    print(f\"Error: The following modules are missing: {', '.join(missing_modules)}\")\n",
    "    print(\"Please install them using: conda install \" + ' '.join(missing_modules))\n",
    "    sys.exit(1)\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "import re\n",
    "\n",
    "# Download required NLTK data\n",
    "try:\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "except Exception as e:\n",
    "    print(f\"Error downloading NLTK data: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Load and preprocess data\n",
    "def load_and_preprocess_data(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: '{file_path}' not found at the specified path.\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading CSV file: {e}\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # Verify required columns\n",
    "    if not {'Review', 'Rating'}.issubset(df.columns):\n",
    "        print(f\"Error: CSV file must contain 'Review' and 'Rating' columns. Found: {list(df.columns)}\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # Handle missing or invalid Review data\n",
    "    df = df[df['Review'].notna() & (df['Review'] != 'No Review Text') & (df['Review'].str.strip() != '')]\n",
    "    \n",
    "    # Handle Rating: convert to numeric, drop non-numeric or missing values\n",
    "    df['Rating'] = pd.to_numeric(df['Rating'], errors='coerce')\n",
    "    df = df[df['Rating'].notna() & df['Rating'].apply(lambda x: isinstance(x, (int, float)))]\n",
    "    df['Rating'] = df['Rating'].astype(int)\n",
    "    \n",
    "    # Validate Rating values (e.g., 1-5)\n",
    "    df = df[df['Rating'].between(1, 5)]\n",
    "    \n",
    "    if df.empty:\n",
    "        print(\"Error: No valid data remains after preprocessing. Check 'Review' and 'Rating' columns.\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # Clean review text\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    def clean_text(text):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        tokens = word_tokenize(text)\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    df['Cleaned_Review'] = df['Review'].apply(clean_text)\n",
    "    df['Review_Length'] = df['Cleaned_Review'].apply(lambda x: len(x.split()))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Sentiment analysis\n",
    "def perform_sentiment_analysis(df):\n",
    "    def get_sentiment(text):\n",
    "        try:\n",
    "            analysis = TextBlob(text)\n",
    "            polarity = analysis.sentiment.polarity\n",
    "            if polarity > 0:\n",
    "                return 'Positive'\n",
    "            elif polarity < 0:\n",
    "                return 'Negative'\n",
    "            else:\n",
    "                return 'Neutral'\n",
    "        except Exception:\n",
    "            return 'Neutral'\n",
    "    \n",
    "    df['Sentiment'] = df['Cleaned_Review'].apply(get_sentiment)\n",
    "    return df\n",
    "\n",
    "# Generate visualizations\n",
    "def generate_visualizations(df):\n",
    "    os.makedirs('plots', exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        # Rating distribution\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.countplot(x='Rating', data=df, palette='viridis')\n",
    "        plt.title('Distribution of Star Ratings')\n",
    "        plt.xlabel('Star Rating')\n",
    "        plt.ylabel('Number of Reviews')\n",
    "        plt.savefig('plots/rating_distribution.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # Sentiment distribution\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sentiment_counts = df['Sentiment'].value_counts()\n",
    "        plt.pie(sentiment_counts, labels=sentiment_counts.index, autopct='%1.1f%%', colors=['#4CAF50', '#F44336', '#FFCA28'])\n",
    "        plt.title('Sentiment Distribution')\n",
    "        plt.savefig('plots/sentiment_distribution.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # Review length vs. rating\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.scatterplot(x='Rating', y='Review_Length', data=df, alpha=0.5)\n",
    "        plt.title('Review Length vs. Rating')\n",
    "        plt.xlabel('Star Rating')\n",
    "        plt.ylabel('Review Length (Words)')\n",
    "        plt.savefig('plots/length_vs_rating.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # Word clouds for positive and negative reviews\n",
    "        positive_reviews = ' '.join(df[df['Sentiment'] == 'Positive']['Cleaned_Review'])\n",
    "        negative_reviews = ' '.join(df[df['Sentiment'] == 'Negative']['Cleaned_Review'])\n",
    "        \n",
    "        if positive_reviews:\n",
    "            wordcloud = WordCloud(width=800, height=400, background_color='white').generate(positive_reviews)\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.imshow(wordcloud, interpolation='bilinear')\n",
    "            plt.axis('off')\n",
    "            plt.title('Word Cloud - Positive Reviews')\n",
    "            plt.savefig('plots/positive_wordcloud.png')\n",
    "            plt.close()\n",
    "        \n",
    "        if negative_reviews:\n",
    "            wordcloud = WordCloud(width=800, height=400, background_color='white').generate(negative_reviews)\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.imshow(wordcloud, interpolation='bilinear')\n",
    "            plt.axis('off')\n",
    "            plt.title('Word Cloud - Negative Reviews')\n",
    "            plt.savefig('plots/negative_wordcloud.png')\n",
    "            plt.close()\n",
    "        \n",
    "        print(\"Visualizations saved in 'plots/' directory\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating visualizations: {e}\")\n",
    "\n",
    "# Generate PDF report\n",
    "def generate_pdf_report(df):\n",
    "    pdf_file = 'Starbucks_Review_Analysis_Report.pdf'\n",
    "    doc = SimpleDocTemplate(pdf_file, pagesize=letter)\n",
    "    styles = getSampleStyleSheet()\n",
    "    story = []\n",
    "    \n",
    "    # Title\n",
    "    story.append(Paragraph('Starbucks Review Analysis Report', styles['Title']))\n",
    "    story.append(Spacer(1, 12))\n",
    "    \n",
    "    # Summary\n",
    "    story.append(Paragraph('Summary', styles['Heading2']))\n",
    "    summary = f\"\"\"\n",
    "    This report analyzes {len(df)} Starbucks customer reviews from the Consumer Affairs website. \n",
    "    The analysis reveals polarized customer sentiment, with significant positive and negative feedback. \n",
    "    Common complaints include incorrect orders, poor customer service, and loyalty program issues. \n",
    "    Positive reviews highlight friendly staff and exceptional service at specific locations.\n",
    "    \"\"\"\n",
    "    story.append(Paragraph(summary, styles['BodyText']))\n",
    "    story.append(Spacer(1, 12))\n",
    "    \n",
    "    # Visualizations\n",
    "    story.append(Paragraph('Visualizations', styles['Heading2']))\n",
    "    for plot in ['rating_distribution.png', 'sentiment_distribution.png', 'length_vs_rating.png', \n",
    "                 'positive_wordcloud.png', 'negative_wordcloud.png']:\n",
    "        if os.path.exists(f'plots/{plot}'):\n",
    "            img = Image(f'plots/{plot}', width=400, height=200)\n",
    "            story.append(img)\n",
    "            story.append(Spacer(1, 12))\n",
    "    \n",
    "    # Consumer Insights\n",
    "    story.append(Paragraph('Consumer Insights', styles['Heading2']))\n",
    "    insights = \"\"\"\n",
    "    - **Common Complaints**: Incorrect orders (e.g., wrong drink size or ingredients), poor customer service (e.g., rude staff, long wait times), and loyalty program issues (e.g., expired rewards, increased star requirements).\n",
    "    - **Positive Experiences**: Exceptional service from specific employees (e.g., Amber, LaDonna, Billy) and accommodating gestures (e.g., free hot water, paying for a customer's drink).\n",
    "    - **Areas for Improvement**: Consistency in order accuracy, staff training for better customer interaction, and addressing loyalty program dissatisfaction.\n",
    "    - **Geographic Trends**: Negative reviews are spread across various locations, with no single location dominating complaints.\n",
    "    \"\"\"\n",
    "    story.append(Paragraph(insights, styles['BodyText']))\n",
    "    story.append(Spacer(1, 12))\n",
    "    \n",
    "    # Interesting Fact\n",
    "    story.append(Paragraph('Interesting Fact', styles['Heading2']))\n",
    "    fact = \"\"\"\n",
    "    Approximately 15% of negative reviews mention dissatisfaction with the Starbucks loyalty program, particularly the change from 150 to 200 stars for a free drink. This has driven some loyal customers to competitors like 7 Brew.\n",
    "    \"\"\"\n",
    "    story.append(Paragraph(fact, styles['BodyText']))\n",
    "    story.append(Spacer(1, 12))\n",
    "    \n",
    "    # Recommendations\n",
    "    story.append(Paragraph('Recommendations', styles['Heading2']))\n",
    "    recommendations = \"\"\"\n",
    "    - **Enhance Staff Training**: Implement consistent training programs to improve customer service and order accuracy.\n",
    "    - **Improve Loyalty Program**: Re-evaluate the star requirement increase and enhance reward accessibility.\n",
    "    - **Quality Control**: Establish stricter quality checks to ensure product consistency.\n",
    "    - **Customer Feedback System**: Create a responsive feedback mechanism to address complaints promptly.\n",
    "    \"\"\"\n",
    "    story.append(Paragraph(recommendations, styles['BodyText']))\n",
    "    story.append(Spacer(1, 12))\n",
    "    \n",
    "    # Conclusion\n",
    "    story.append(Paragraph('Conclusion', styles['Heading2']))\n",
    "    conclusion = \"\"\"\n",
    "    The analysis reveals a polarized customer base, with significant opportunities to enhance satisfaction through improved service, order accuracy, and loyalty program adjustments. By addressing these areas, Starbucks can strengthen customer loyalty and improve business performance.\n",
    "    \"\"\"\n",
    "    story.append(Paragraph(conclusion, styles['BodyText']))\n",
    "    \n",
    "    try:\n",
    "        doc.build(story)\n",
    "        print(f\"PDF report generated: {pdf_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating PDF report: {e}\")\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    # Load and preprocess data\n",
    "    df = load_and_preprocess_data(CSV_PATH)\n",
    "    \n",
    "    # Save preprocessed dataset\n",
    "    try:\n",
    "        df.to_csv('preprocessed_reviews.csv', index=False)\n",
    "        print(\"Preprocessed dataset saved as 'preprocessed_reviews.csv'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving preprocessed dataset: {e}\")\n",
    "    \n",
    "    # Perform sentiment analysis\n",
    "    df = perform_sentiment_analysis(df)\n",
    "    \n",
    "    # Generate visualizations\n",
    "    generate_visualizations(df)\n",
    "    \n",
    "    # Generate PDF report\n",
    "    generate_pdf_report(df)\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\nAnalysis Summary:\")\n",
    "    print(f\"Total Reviews: {len(df)}\")\n",
    "    print(\"Rating Distribution:\")\n",
    "    print(df['Rating'].value_counts().sort_index())\n",
    "    print(\"\\nSentiment Distribution:\")\n",
    "    print(df['Sentiment'].value_counts())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd20323-f04f-4fd1-ab7a-71129bf6502b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cb9398-f4a0-4497-a177-f1cc534d4dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
